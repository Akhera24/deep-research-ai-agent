# Deep Research AI Agent - Complete Implementation Plan

## Executive Summary

This document outlines the complete architecture, implementation strategy, and technical specifications for building a production-grade autonomous research agent capable of conducting comprehensive investigations on individuals and entities.

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Technology Stack](#technology-stack)
3. [System Design](#system-design)
4. [Multi-Agent Architecture](#multi-agent-architecture)
5. [Evaluation Framework](#evaluation-framework)
6. [Implementation Phases](#implementation-phases)
7. [File Structure](#file-structure)
8. [API Configuration](#api-configuration)
9. [Testing Strategy](#testing-strategy)
10. [Production Deployment](#production-deployment)

---

## 1. Architecture Overview

### Core Principles
- **Modularity**: Each component is independently testable and replaceable
- **Scalability**: Horizontal scaling for concurrent research operations
- **Reliability**: Comprehensive error handling and fallback mechanisms
- **Observability**: Full logging, monitoring, and audit trails
- **Security**: API key management, rate limiting, data encryption

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface (Frontend)                â”‚
â”‚                   React + TypeScript + Tailwind              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway (FastAPI)                     â”‚
â”‚            Authentication, Rate Limiting, Validation         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph Orchestration Layer                   â”‚
â”‚        State Management, Agent Coordination, Workflow        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚              â”‚                â”‚
     â†“             â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Research â”‚  â”‚Analysis â”‚  â”‚  Risk    â”‚  â”‚  Connection     â”‚
â”‚ Agent   â”‚  â”‚ Agent   â”‚  â”‚Assessmentâ”‚  â”‚  Mapping Agent  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Model Layer                         â”‚
â”‚   Claude Opus 4 | Gemini 2.5 | GPT-4.1 | Perplexity         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Sources Layer                        â”‚
â”‚  Web Search | Social Media | Public Records | News Archives  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Persistence Layer                    â”‚
â”‚        PostgreSQL | Redis Cache | Vector DB (Pinecone)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Technology Stack

### Backend Core
- **Framework**: FastAPI 0.109+ (async support, automatic documentation)
- **Agent Orchestration**: LangGraph 0.2+ (state management, workflow control)
- **Task Queue**: Celery + Redis (background jobs, rate limiting)
- **Database**: PostgreSQL 16+ (relational data, JSONB support)
- **Cache**: Redis 7+ (API response caching, session management)
- **Vector Store**: Pinecone or Weaviate (semantic search, entity embeddings)

### AI Models & APIs

#### Primary Models (Multi-Model Strategy)
1. **Claude Opus 4** (Anthropic)
   - **Use Case**: Deep analysis, risk assessment, nuanced reasoning
   - **Strengths**: Superior reasoning, ethical considerations, context handling
   - **Rate Limit**: 50 req/min (tier 4)
   
2. **Gemini 2.5 Pro** (Google)
   - **Use Case**: Multi-modal analysis, document processing, fact extraction
   - **Strengths**: Large context window, multimodal capabilities
   - **Rate Limit**: 360 req/min

3. **GPT-4.1 Turbo** (OpenAI)
   - **Use Case**: Structured output, function calling, rapid iterations
   - **Strengths**: Reliable structured output, fast response times
   - **Rate Limit**: 500 req/min (tier 5)

4. **Perplexity API** (Optional)
   - **Use Case**: Real-time web search with citations
   - **Strengths**: Search-optimized, current information
   - **Rate Limit**: 50 req/min

#### Supporting Services
- **Search APIs**: 
  - Brave Search API (privacy-focused, 2000 queries/month free)
  - Serper API (Google search, $50/month for 20k queries)
  - SerpAPI (backup, 100 free searches/month)
  
- **Data Enrichment**:
  - Clearbit API (company/people data)
  - Hunter.io (email verification)
  - FullContact (social profile aggregation)

### Frontend Stack
- **Framework**: React 18+ with TypeScript
- **Build Tool**: Vite 5+
- **UI Library**: shadcn/ui + Tailwind CSS
- **State Management**: Zustand or TanStack Query
- **Charts**: Recharts or D3.js (connection visualization)
- **Real-time**: Socket.io (progress updates)

### DevOps & Infrastructure
- **Containerization**: Docker + Docker Compose
- **CI/CD**: GitHub Actions
- **Monitoring**: Sentry (errors), Grafana (metrics), Prometheus
- **Logging**: ELK Stack or Loki
- **Deployment**: AWS ECS/EKS or Vercel + Railway

---

## 3. System Design

### 3.1 Core Components

#### A. Research Orchestrator
```python
class ResearchOrchestrator:
    """
    Main orchestration engine using LangGraph.
    Manages the research workflow state machine.
    """
    - Initial Query Processing
    - Multi-Stage Search Planning
    - Agent Coordination
    - Result Aggregation
    - Quality Assurance
```

#### B. Search Strategy Engine
```python
class SearchStrategyEngine:
    """
    Adaptive search strategy that learns from previous results.
    Implements consecutive search with dynamic refinement.
    """
    - Query Generation
    - Search Depth Calculation
    - Topic Prioritization
    - Redundancy Elimination
    - Coverage Analysis
```

#### C. Multi-Model Router
```python
class ModelRouter:
    """
    Intelligent routing of requests to optimal AI model.
    Includes fallback mechanisms and load balancing.
    """
    - Task Classification
    - Model Selection
    - Load Balancing
    - Fallback Logic
    - Cost Optimization
```

### 3.2 Data Flow

```
User Query â†’ Initial Analysis â†’ Search Strategy Generation
                â†“
    Multi-Stage Search Execution (Parallel + Sequential)
                â†“
    Fact Extraction â†’ Verification â†’ Confidence Scoring
                â†“
    Risk Analysis â†’ Pattern Recognition â†’ Connection Mapping
                â†“
    Report Generation â†’ Quality Check â†’ User Presentation
```

### 3.3 State Management (LangGraph)

```python
class ResearchState(TypedDict):
    """State object passed through LangGraph workflow"""
    query: str
    target_entity: Dict[str, Any]
    search_history: List[SearchResult]
    facts: List[Fact]
    connections: List[Connection]
    risk_flags: List[RiskFlag]
    confidence_scores: Dict[str, float]
    current_stage: str
    iteration_count: int
    max_iterations: int
    errors: List[Error]
```

---

## 4. Multi-Agent Architecture

### 4.1 Agent Roles & Responsibilities

#### Agent 1: Research Coordinator Agent
- **Model**: Claude Opus 4
- **Responsibilities**:
  - Overall strategy planning
  - Prioritization of research areas
  - Quality assessment of findings
  - Final report synthesis
- **Inputs**: User query, previous results
- **Outputs**: Search plan, priority list, quality scores

#### Agent 2: Data Collection Agent
- **Model**: Gemini 2.5 Pro
- **Responsibilities**:
  - Web search execution
  - Multi-source data gathering
  - Document processing
  - Initial fact extraction
- **Inputs**: Search queries, URLs
- **Outputs**: Raw data, extracted facts

#### Agent 3: Analysis & Verification Agent
- **Model**: GPT-4.1 Turbo
- **Responsibilities**:
  - Fact verification
  - Cross-referencing
  - Contradiction detection
  - Confidence scoring
- **Inputs**: Extracted facts, source metadata
- **Outputs**: Verified facts with confidence scores

#### Agent 4: Risk Assessment Agent
- **Model**: Claude Opus 4
- **Responsibilities**:
  - Risk pattern identification
  - Red flag detection
  - Anomaly analysis
  - Severity scoring
- **Inputs**: Verified facts, behavioral patterns
- **Outputs**: Risk assessment report

#### Agent 5: Connection Mapping Agent
- **Model**: Gemini 2.5 Pro
- **Responsibilities**:
  - Relationship identification
  - Network analysis
  - Timeline construction
  - Entity linking
- **Inputs**: Facts, entities, events
- **Outputs**: Connection graph, timeline

### 4.2 Agent Communication Protocol

```python
class AgentMessage:
    sender: str
    receiver: str
    message_type: str
    payload: Dict[str, Any]
    priority: int
    timestamp: datetime
```

### 4.3 LangGraph Workflow

```python
from langgraph.graph import StateGraph, END

def create_research_graph():
    workflow = StateGraph(ResearchState)
    
    # Add nodes (agents)
    workflow.add_node("coordinator", coordinator_agent)
    workflow.add_node("collector", data_collection_agent)
    workflow.add_node("analyzer", analysis_agent)
    workflow.add_node("risk_assessor", risk_assessment_agent)
    workflow.add_node("mapper", connection_mapper_agent)
    
    # Define edges (transitions)
    workflow.set_entry_point("coordinator")
    workflow.add_edge("coordinator", "collector")
    workflow.add_edge("collector", "analyzer")
    workflow.add_conditional_edges(
        "analyzer",
        should_continue_research,
        {
            "continue": "collector",
            "assess_risk": "risk_assessor"
        }
    )
    workflow.add_edge("risk_assessor", "mapper")
    workflow.add_edge("mapper", END)
    
    return workflow.compile()
```

---

## 5. Evaluation Framework

### 5.1 Test Personas

Create 3 comprehensive test personas with varying complexity:


### 5.2 Evaluation Metrics

```python
class EvaluationMetrics:
    # Discovery Metrics
    discovery_rate: float  # % of hidden facts found
    false_positive_rate: float  # % of incorrect facts
    
    # Depth Metrics
    avg_search_depth: int  # Average depth of discoveries
    max_depth_achieved: int  # Deepest fact discovered
    
    # Efficiency Metrics
    searches_per_fact: float  # Search efficiency
    time_per_fact: float  # Time efficiency
    cost_per_research: float  # API cost per operation
    
    # Quality Metrics
    confidence_accuracy: float  # How accurate are confidence scores
    source_reliability: float  # Quality of sources used
    connection_validity: float  # Accuracy of mapped connections
    
    # Coverage Metrics
    topic_coverage: float  # % of relevant topics explored
    temporal_coverage: float  # Time period coverage
    source_diversity: float  # Variety of sources used
```

### 5.3 Evaluation Dataset Structure

```json
{
  "persona_id": "P001",
  "name": "Person 1",
  "difficulty": "easy",
  "ground_truth": {
    "basic_facts": [
      {
        "fact": "CEO of TechVenture Inc.",
        "verification_url": "https://techventure.com/about",
        "difficulty": 1,
        "should_find": true
      }
    ],
    "hidden_facts": [
      {
        "fact": "Board member of StartupX (2015-2016, company dissolved)",
        "verification_sources": ["archive.org/startupx", "SEC filings"],
        "difficulty": 3,
        "search_depth_required": 3,
        "keywords": ["StartupX", "board", "2015"],
        "should_find": true
      }
    ],
    "risk_indicators": [
      {
        "indicator": "Previous business failure",
        "severity": "low",
        "evidence_count": 2,
        "should_flag": true
      }
    ],
    "connections": [
      {
        "entity_1": "",
        "entity_2": "",
        "relationship": "co-founder",
        "time_period": "2017-2018",
        "should_discover": true,
        "connection_strength": 0.9
      }
    ]
  },
  "evaluation_criteria": {
    "minimum_discovery_rate": 0.85,
    "maximum_false_positives": 0.05,
    "required_search_depth": 4,
    "expected_searches": 12
  }
}
```

---

## 6. File Structure

```
deep-research-agent/
â”œâ”€â”€ README.md
â”œâ”€â”€ IMPLEMENTATION_PLAN.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py              # Environment configuration
â”‚   â”œâ”€â”€ api_keys.py              # API key management
â”‚   â”œâ”€â”€ model_config.py          # Model parameters
â”‚   â””â”€â”€ logging_config.py        # Logging setup
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_agent.py        # Base agent class
â”‚   â”‚   â”œâ”€â”€ coordinator.py       # Research coordinator agent
â”‚   â”‚   â”œâ”€â”€ collector.py         # Data collection agent
â”‚   â”‚   â”œâ”€â”€ analyzer.py          # Analysis & verification agent
â”‚   â”‚   â”œâ”€â”€ risk_assessor.py     # Risk assessment agent
â”‚   â”‚   â””â”€â”€ mapper.py            # Connection mapping agent
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # LangGraph orchestration
â”‚   â”‚   â”œâ”€â”€ state_manager.py     # State management
â”‚   â”‚   â”œâ”€â”€ workflow.py          # Workflow definitions
â”‚   â”‚   â””â”€â”€ agent_protocol.py    # Agent communication
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router.py            # Multi-model router
â”‚   â”‚   â”œâ”€â”€ claude_client.py     # Claude API wrapper
â”‚   â”‚   â”œâ”€â”€ gemini_client.py     # Gemini API wrapper
â”‚   â”‚   â”œâ”€â”€ openai_client.py     # OpenAI API wrapper
â”‚   â”‚   â””â”€â”€ fallback.py          # Fallback logic
â”‚   â”‚
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ strategy.py          # Search strategy engine
â”‚   â”‚   â”œâ”€â”€ query_generator.py   # Query generation
â”‚   â”‚   â”œâ”€â”€ search_executor.py   # Search execution
â”‚   â”‚   â”œâ”€â”€ brave_search.py      # Brave Search API
â”‚   â”‚   â”œâ”€â”€ serper.py            # Serper API
â”‚   â”‚   â””â”€â”€ deduplicator.py      # Result deduplication
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fact_extractor.py    # Fact extraction
â”‚   â”‚   â”œâ”€â”€ entity_recognizer.py # Named entity recognition
â”‚   â”‚   â”œâ”€â”€ parser.py            # Data parsing
â”‚   â”‚   â””â”€â”€ normalizer.py        # Data normalization
â”‚   â”‚
â”‚   â”œâ”€â”€ verification/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ verifier.py          # Fact verification
â”‚   â”‚   â”œâ”€â”€ cross_reference.py   # Cross-referencing
â”‚   â”‚   â”œâ”€â”€ confidence_scorer.py # Confidence scoring
â”‚   â”‚   â””â”€â”€ source_validator.py  # Source validation
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ risk_analyzer.py     # Risk pattern analysis
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py  # Pattern detection
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py  # Anomaly detection
â”‚   â”‚   â””â”€â”€ severity_scorer.py   # Severity scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ mapping/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ connection_mapper.py # Connection mapping
â”‚   â”‚   â”œâ”€â”€ graph_builder.py     # Graph construction
â”‚   â”‚   â”œâ”€â”€ timeline_builder.py  # Timeline construction
â”‚   â”‚   â””â”€â”€ entity_linker.py     # Entity linking
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py            # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ repositories.py      # Data access layer
â”‚   â”‚   â”œâ”€â”€ migrations/          # Database migrations
â”‚   â”‚   â””â”€â”€ redis_cache.py       # Redis caching
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ research.py      # Research endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation.py    # Evaluation endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py        # Health check
â”‚   â”‚   â”œâ”€â”€ dependencies.py      # Dependency injection
â”‚   â”‚   â”œâ”€â”€ middleware.py        # Custom middleware
â”‚   â”‚   â””â”€â”€ websocket.py         # WebSocket for real-time updates
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ rate_limiter.py      # Rate limiting
â”‚       â”œâ”€â”€ retry.py             # Retry logic
â”‚       â”œâ”€â”€ validators.py        # Input validation
â”‚       â”œâ”€â”€ formatters.py        # Output formatting
â”‚       â””â”€â”€ helpers.py           # Helper functions
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ personas/
â”‚   â”‚   â”œâ”€â”€ persona_01_easy.json
â”‚   â”‚   â”œâ”€â”€ persona_02_medium.json
â”‚   â”‚   â””â”€â”€ persona_03_hard.json
â”‚   â”œâ”€â”€ evaluator.py             # Evaluation engine
â”‚   â”œâ”€â”€ metrics.py               # Metrics calculation
â”‚   â””â”€â”€ reports/                 # Generated reports
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”‚   â”œâ”€â”€ test_search.py
â”‚   â”‚   â”œâ”€â”€ test_extraction.py
â”‚   â”‚   â””â”€â”€ test_verification.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_workflow.py
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â””â”€â”€ test_e2e.py
â”‚   â””â”€â”€ fixtures/
â”‚       â””â”€â”€ test_data.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ResearchForm.tsx
â”‚       â”‚   â”œâ”€â”€ ProgressDisplay.tsx
â”‚       â”‚   â”œâ”€â”€ ResultsView.tsx
â”‚       â”‚   â”œâ”€â”€ ConnectionGraph.tsx
â”‚       â”‚   â””â”€â”€ RiskAssessment.tsx
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â”œâ”€â”€ useResearch.ts
â”‚       â”‚   â””â”€â”€ useWebSocket.ts
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â””â”€â”€ client.ts
â”‚       â””â”€â”€ types/
â”‚           â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_db.py
â”‚   â”œâ”€â”€ test_apis.py
â”‚   â”œâ”€â”€ generate_personas.py
â”‚   â””â”€â”€ run_evaluation.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ AGENTS.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ CONTRIBUTING.md
â”‚
â””â”€â”€ logs/
    â””â”€â”€ .gitkeep
```

---

## 7. API Configuration

### 7.1 Environment Variables

```env
# .env.example

# API Keys
ANTHROPIC_API_KEY=sk-ant-xxx
GOOGLE_API_KEY=AIzaxxx
OPENAI_API_KEY=sk-xxx
PERPLEXITY_API_KEY=pplx-xxx

# Search APIs
BRAVE_API_KEY=BSAxxx
SERPER_API_KEY=xxx
SERPAPI_KEY=xxx

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/research_db
REDIS_URL=redis://localhost:6379/0

# Vector DB
PINECONE_API_KEY=xxx
PINECONE_ENVIRONMENT=xxx

# Application
ENVIRONMENT=development
DEBUG=True
LOG_LEVEL=INFO
MAX_CONCURRENT_REQUESTS=10

# Rate Limits (requests per minute)
CLAUDE_RATE_LIMIT=50
GEMINI_RATE_LIMIT=360
OPENAI_RATE_LIMIT=500

# Search Limits
MAX_SEARCH_ITERATIONS=50
MAX_CONCURRENT_SEARCHES=5
SEARCH_TIMEOUT=30

# Frontend
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000/ws
```

### 7.2 API Key Setup Checklist

```python
# scripts/test_apis.py

import os
from anthropic import Anthropic
from google.generativeai import configure as configure_gemini
from openai import OpenAI

def test_api_keys():
    """Test all API keys are valid and have sufficient quota"""
    
    results = {}
    
    # Test Anthropic
    try:
        client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        response = client.messages.create(
            model="claude-opus-4-20250514",
            max_tokens=10,
            messages=[{"role": "user", "content": "Hi"}]
        )
        results["anthropic"] = "âœ… Success"
    except Exception as e:
        results["anthropic"] = f"âŒ Failed: {str(e)}"
    
    # Test Google Gemini
    try:
        configure_gemini(api_key=os.getenv("GOOGLE_API_KEY"))
        # Test call here
        results["gemini"] = "âœ… Success"
    except Exception as e:
        results["gemini"] = f"âŒ Failed: {str(e)}"
    
    # Test OpenAI
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=10
        )
        results["openai"] = "âœ… Success"
    except Exception as e:
        results["openai"] = f"âŒ Failed: {str(e)}"
    
    # Print results
    print("\nğŸ”‘ API Key Test Results:")
    print("=" * 50)
    for service, result in results.items():
        print(f"{service.upper()}: {result}")
    
    return all("âœ…" in r for r in results.values())

if __name__ == "__main__":
    test_api_keys()
```

---

## 8. Testing Strategy

### 8.1 Unit Tests
- Individual agent functionality
- Search strategy algorithms
- Fact extraction accuracy
- Verification logic
- Connection mapping algorithms

### 8.2 Integration Tests
- Agent communication
- LangGraph workflow
- Database operations
- API endpoint functionality
- WebSocket real-time updates

### 8.3 End-to-End Tests
- Complete research workflows
- Evaluation personas
- Performance benchmarks
- Error recovery
- Rate limit handling

### 8.4 Load Tests
- Concurrent research operations
- API rate limiting
- Database connection pooling
- Memory usage
- Response times

---

## 9. Production Deployment

### 9.1 Infrastructure Requirements

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/research
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./logs:/app/logs
    
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: research
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    
  celery:
    build: .
    command: celery -A src.tasks worker --loglevel=info
    depends_on:
      - redis
      - db
    
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://api:8000

volumes:
  postgres_data:
  redis_data:
```

### 9.2 Monitoring & Logging

- **Application Monitoring**: Sentry for error tracking
- **Performance Monitoring**: Prometheus + Grafana
- **Log Aggregation**: ELK Stack or Loki
- **Uptime Monitoring**: Better Uptime or Pingdom
- **Cost Tracking**: Custom dashboard for API usage

### 9.3 Security Considerations

- API key rotation policy
- Rate limiting per user
- Input sanitization
- SQL injection prevention
- XSS protection
- CORS configuration
- Authentication & authorization
- Data encryption at rest
- Audit logging

---
## Conclusion

This implementation plan provides a comprehensive roadmap for building a production-grade deep research AI agent. The architecture is designed for scalability, maintainability, and extensibility. 

**Key Factors**:
- Robust multi-model integration
- Intelligent search strategies
- Comprehensive evaluation framework
- Production-ready infrastructure
- Excellent documentation

